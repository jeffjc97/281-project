{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdrs = None\n",
    "data = None\n",
    "\n",
    "# parse data from song features\n",
    "with open(\"data/random_song_features.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    all_rows = list(reader)\n",
    "    hdrs = all_rows[0]\n",
    "    data = all_rows[1:]\n",
    "    \n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "pop_index = hdrs.index('popularity')\n",
    "all_id = data[:,:2]\n",
    "data = data[:,2:]\n",
    "y_data = data[:,pop_index - 2]\n",
    "x_data = np.delete(data, pop_index - 2, 1)\n",
    "y_data = y_data.astype(np.float)\n",
    "x_data = x_data.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 39060\n",
      "Test:  4340\n"
     ]
    }
   ],
   "source": [
    "N_ROWS = len(x_data)\n",
    "N_TRAIN = int(0.9 * N_ROWS)\n",
    "N_TEST = N_ROWS - N_TRAIN\n",
    "x_train = x_data[:N_TRAIN]\n",
    "y_train = y_data[:N_TRAIN]\n",
    "x_test = x_data[N_TRAIN:]\n",
    "y_test = y_data[N_TRAIN:]\n",
    "print(\"Train: {}\\nTest:  {}\".format(N_TRAIN, N_ROWS - N_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# N_STEPS, INCREMENTS, LR = 20000, 10, 0.001\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "# net     = torch.nn.Sequential(OrderedDict([\n",
    "#     ('lin1', torch.nn.Linear(N_FEATURES, 1)),\n",
    "# #     ('relu', torch.nn.ReLU()),\n",
    "# #     ('lin2', torch.nn.Linear(5, 1))\n",
    "# ]))\n",
    "# optim   = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "# losses = []\n",
    "# last_time = time.time()\n",
    "# for step in range(N_STEPS):\n",
    "#     pred = net.forward(x_train)\n",
    "#     loss = loss_fn(pred, y_train)\n",
    "#     if (step + 1) % (N_STEPS // INCREMENTS) == 0:\n",
    "#         curr_time = time.time()\n",
    "#         elapsed = curr_time - last_time\n",
    "#         last_time = curr_time\n",
    "#         print(\"Done with batch {:02d}/{:02d}, elapsed time {:04.2f}; loss is {:.2f} \".format(\n",
    "#             (step + 1) // (N_STEPS // INCREMENTS), INCREMENTS, elapsed, loss.data.numpy()[0]\n",
    "#         ))\n",
    "#     losses.append(loss.data.numpy()[0])\n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on regressor linear\tFit time: 0.04\n",
      "Starting on regressor bayesian\tFit time: 0.06\n",
      "Starting on regressor forest-1\tFit time: 0.94\n",
      "Starting on regressor forest-2\tFit time: 0.92\n",
      "Starting on regressor forest-3\tFit time: 0.93\n",
      "Starting on regressor forest-4\tFit time: 1.03\n",
      "Starting on regressor forest-5\tFit time: 1.03\n",
      "Starting on regressor forest-10\tFit time: 2.08\n",
      "Starting on regressor forest-20\tFit time: 3.31\n",
      "Starting on regressor forest-30\tFit time: 4.96\n",
      "Starting on regressor forest-40\tFit time: 7.29\n",
      "Starting on regressor forest-50\tFit time: 9.56\n",
      "Starting on regressor forest-100\tFit time: 16.33\n",
      "Starting on regressor forest-200\tFit time: 35.43\n",
      "Starting on regressor forest-300\tFit time: 56.60\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "\n",
    "regressors = {\n",
    "    'linear': LinearRegression(),\n",
    "    'bayesian': BayesianRidge()\n",
    "}\n",
    "estimators = [1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 100, 200, 300]\n",
    "for i in estimators:\n",
    "    regressors[\"forest-{}\".format(i)] = RandomForestRegressor(n_estimators=i, n_jobs=8)\n",
    "\n",
    "data = {}\n",
    "for name, regressor in regressors.items():\n",
    "    print(\"Starting on regressor {}\".format(name), end='\\t')\n",
    "    start_time = time.time()\n",
    "    regressor.fit(x_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(\"Fit time: {:.2f}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 2.12\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(n_jobs=8, tol=10 ** -10)\n",
    "start_time = time.time()\n",
    "lr.fit(x_train, (y_train >= 80).astype(np.int))\n",
    "end_time = time.time()\n",
    "print(\"Fit time: {:.2f}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4315 4314\n"
     ]
    }
   ],
   "source": [
    "pred = lr.predict(x_test)\n",
    "print(sum(pred))\n",
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    val = y_test[i]\n",
    "    if val < 80:\n",
    "        total += 1\n",
    "        if pred[i] == 0:\n",
    "            correct += 1\n",
    "print(total, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing results for regressor linear...\tAverage Error: 8.44, Test RMSE: 11.31\n",
      "Analyzing results for regressor bayesian...\tAverage Error: 8.44, Test RMSE: 11.31\n",
      "Analyzing results for regressor forest-1...\tAverage Error: 10.47, Test RMSE: 14.17\n",
      "Done analyzing results!\n"
     ]
    }
   ],
   "source": [
    "for name, regressor in regressors.items():\n",
    "    print(\"Analyzing results for regressor {}...\".format(name), end='\\t')\n",
    "    pred = regressor.predict(x_test)\n",
    "    errs = Variable(torch.Tensor(pred - y_test))\n",
    "    loss = errs.pow(2).sum()\n",
    "    avg_err = errs.abs().mean().data.numpy()[0]\n",
    "    rmse = np.sqrt(loss.data.numpy()[0] / N_TEST)\n",
    "    data[name] = [avg_err, rmse]\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.hist(errs.data.numpy(), bins=100)\n",
    "    plt.xlabel(\"Popularity Prediction Error\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\n",
    "        'Prediction Errors for Model \\\"{}\\\"'\n",
    "        '\\nAverage Error: {:4.2f}, Test RMSE: {:4.2f}'.format(\n",
    "        name, avg_err, rmse\n",
    "    ))\n",
    "    plt.savefig(\"results/v2-split90-{}.png\".format(name))\n",
    "    print(\"Average Error: {:4.2f}, Test RMSE: {:4.2f}\".format(\n",
    "        avg_err, rmse\n",
    "    ))\n",
    "\n",
    "with open(\"results/v2-split90-data.csv\", \"w+\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Model', 'Average Error', 'RMSE'])\n",
    "    for model in data:\n",
    "        writer.writerow([model] + data[model])\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(estimators, list(map(\n",
    "    lambda e: data['forest-{}'.format(e)][0], estimators\n",
    ")))\n",
    "plt.title('Random Forest Regressor Average Prediction Error vs. # Estimators')\n",
    "plt.xlabel('# Estimators')\n",
    "plt.ylabel('Average Prediction Error')\n",
    "plt.savefig('results/v2-split90-rfr-err.png')\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(estimators, list(map(\n",
    "    lambda e: data['forest-{}'.format(e)][1], estimators\n",
    ")))\n",
    "plt.title('Random Forest Regressor RMSE vs. # Estimators')\n",
    "plt.xlabel('# Estimators')\n",
    "plt.ylabel('RMSE')\n",
    "plt.savefig('results/v2-split90-rfr-rmse.png')\n",
    "\n",
    "print(\"Done analyzing results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The problem that we aim to is that of predicting a song's popularity based on the song's characteristics. The problem in, its most basic form, takes in a sound file as input and outputs a classification of whether that particular song will be a \"hit\" or not. In our work, we hope to modify our approach in two main ways. First, we will integrate the song's artist into our calculations, as we expect that will allow for better and more applicable performance. Next, we will structure our problem as a regression problem as opposed to a classification problem. This will allow us to have a more granular view of our results and give us the ability to compare songs' relative popularity. \n",
    "\n",
    "Our final model involved using a random forest regressor and resulted in an RMSE of 9.97 and an average error of 7.49, better performance than cited in similar previous work.\n",
    "\n",
    "Our final results concluded that, perhaps unsurprisingly, random forest regressors performed the best out of any of the models we tested, including various forms of linear regression and neural nets we constructed.  The main contributions we make are 1) the observation that other studies are missing key features such as artist popularity and genre, and 2) a more granular method of estimating the success of a song, rather than a binary classification of \"popular or not\".  We were able to predict popularities with L1 and L2 norms of approximately 8 and 10 each (out of a total score of 100), which we believe outperforms previous comparable work.\n",
    "\n",
    "Future work involves integrating lyric analysis into the feature set; we were unable to do so because of the lack of computing time and resources (and a slow API), but we believe that analysis of the lyrics will provide even better results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
