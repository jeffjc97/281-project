{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from torch.autograd import Variable\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdrs = None\n",
    "data = None\n",
    "\n",
    "# parse data from song features\n",
    "with open(\"data/random_song_features.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    all_rows = list(reader)\n",
    "    hdrs = all_rows[0]\n",
    "    data = all_rows[1:]\n",
    "    \n",
    "data = np.array(data)\n",
    "pop_index = hdrs.index('popularity')\n",
    "all_id = data[:,:2]\n",
    "data = data[:,2:]\n",
    "y_data = data[:,pop_index - 2]\n",
    "x_data = np.delete(data, pop_index - 2, 1)\n",
    "y_data = y_data.astype(np.float)\n",
    "x_data = x_data.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 39145\n",
      "Test:  4350\n"
     ]
    }
   ],
   "source": [
    "N_ROWS = len(x_data)\n",
    "N_TRAIN = int(0.9 * N_ROWS)\n",
    "N_TEST = N_ROWS - N_TRAIN\n",
    "x_train = x_data[:N_TRAIN]\n",
    "y_train = y_data[:N_TRAIN]\n",
    "x_test = x_data[N_TRAIN:]\n",
    "y_test = y_data[N_TRAIN:]\n",
    "print(\"Train: {}\\nTest:  {}\".format(N_TRAIN, N_ROWS - N_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# N_STEPS, INCREMENTS, LR = 20000, 10, 0.001\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "# net     = torch.nn.Sequential(OrderedDict([\n",
    "#     ('lin1', torch.nn.Linear(N_FEATURES, 1)),\n",
    "# #     ('relu', torch.nn.ReLU()),\n",
    "# #     ('lin2', torch.nn.Linear(5, 1))\n",
    "# ]))\n",
    "# optim   = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "# losses = []\n",
    "# last_time = time.time()\n",
    "# for step in range(N_STEPS):\n",
    "#     pred = net.forward(x_train)\n",
    "#     loss = loss_fn(pred, y_train)\n",
    "#     if (step + 1) % (N_STEPS // INCREMENTS) == 0:\n",
    "#         curr_time = time.time()\n",
    "#         elapsed = curr_time - last_time\n",
    "#         last_time = curr_time\n",
    "#         print(\"Done with batch {:02d}/{:02d}, elapsed time {:04.2f}; loss is {:.2f} \".format(\n",
    "#             (step + 1) // (N_STEPS // INCREMENTS), INCREMENTS, elapsed, loss.data.numpy()[0]\n",
    "#         ))\n",
    "#     losses.append(loss.data.numpy()[0])\n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on regressor linear\t\tAverage Error: 8.26, Test RMSE: 11.41\n",
      "Starting on regressor forest-1\t\tAverage Error: 11.33, Test RMSE: 15.29\n",
      "Starting on regressor forest-2\t\tAverage Error: 9.76, Test RMSE: 13.17\n",
      "Starting on regressor forest-3\t\tAverage Error: 9.25, Test RMSE: 12.44\n",
      "Starting on regressor forest-4\t\tAverage Error: 8.83, Test RMSE: 11.85\n",
      "Starting on regressor forest-5\t\tAverage Error: 8.69, Test RMSE: 11.78\n",
      "Starting on regressor forest-10\t\tAverage Error: 8.32, Test RMSE: 11.31\n",
      "Starting on regressor forest-20\t\tAverage Error: 8.08, Test RMSE: 11.03\n",
      "Starting on regressor forest-30\t\tAverage Error: 7.97, Test RMSE: 10.91\n",
      "Starting on regressor forest-40\t\tAverage Error: 7.95, Test RMSE: 10.87\n",
      "Starting on regressor forest-50\t\tAverage Error: 7.94, Test RMSE: 10.88\n",
      "Starting on regressor forest-100\t\tAverage Error: 7.87, Test RMSE: 10.80\n",
      "Starting on regressor forest-200\t\tAverage Error: 7.83, Test RMSE: 10.75\n",
      "Starting on regressor forest-300\t\tAverage Error: 7.83, Test RMSE: 10.76\n",
      "\n",
      "Done running models!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "\n",
    "regressors = {\n",
    "    'linear': LinearRegression()\n",
    "}\n",
    "estimators = [1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 100, 200, 300]\n",
    "for i in estimators:\n",
    "    regressors[\"forest-{}\".format(i)] = RandomForestRegressor(n_estimators=i)\n",
    "\n",
    "data = {}\n",
    "for name, regressor in regressors.items():\n",
    "    print(\"Starting on regressor {}\".format(name), end='\\t\\t')\n",
    "    regressor.fit(x_train, y_train)\n",
    "    pred = regressor.predict(x_test)\n",
    "    errs = Variable(torch.Tensor(pred - y_test))\n",
    "    loss = errs.pow(2).sum()\n",
    "    avg_err = errs.abs().mean().data.numpy()[0]\n",
    "    rmse = np.sqrt(loss.data.numpy()[0] / N_TEST)\n",
    "    data[name] = [avg_err, rmse]\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.hist(errs.data.numpy(), bins=100)\n",
    "    plt.xlabel(\"Popularity Prediction Error\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\n",
    "        'Prediction Errors for Model \\\"{}\\\"'\n",
    "        '\\nAverage Error: {:4.2f}, Test RMSE: {:4.2f}'.format(\n",
    "        name, avg_err, rmse\n",
    "    ))\n",
    "    plt.savefig(\"results/v2-split90-{}.png\".format(name))\n",
    "    print(\"Average Error: {:4.2f}, Test RMSE: {:4.2f}\".format(\n",
    "        avg_err, rmse\n",
    "    ))\n",
    "\n",
    "with open(\"results/v2-split90-data.csv\", \"w+\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Model', 'Average Error', 'RMSE'])\n",
    "    for model in data:\n",
    "        writer.writerow([model] + data[model])\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(estimators, list(map(\n",
    "    lambda e: data['forest-{}'.format(e)][0], estimators\n",
    ")))\n",
    "plt.title('Random Forest Regressor Average Prediction Error vs. # Estimators')\n",
    "plt.xlabel('# Estimators')\n",
    "plt.ylabel('Average Prediction Error')\n",
    "plt.savefig('results/v2-split90-rfr-err.png')\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(estimators, list(map(\n",
    "    lambda e: data['forest-{}'.format(e)][1], estimators\n",
    ")))\n",
    "plt.title('Random Forest Regressor RMSE vs. # Estimators')\n",
    "plt.xlabel('# Estimators')\n",
    "plt.ylabel('RMSE')\n",
    "plt.savefig('results/v2-split90-rfr-rmse.png')\n",
    "\n",
    "print(\"\\nDone running models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_regression(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['artist_popularity', 'release_date', 'album_length', 'loudness',\n",
       "       'instrumentalness', 'duration', 'num_segments', 'acousticness',\n",
       "       'start_of_fade_out', 'num_tatums', 'energy', 'num_beats',\n",
       "       'num_sections', 'track_number', 'num_bars', 'danceability',\n",
       "       'valence', 'explicit', 'speechiness', 'time_signature_confidence',\n",
       "       'end_of_fade_in', 'mode_confidence', 'tempo', 'time_signature',\n",
       "       'liveness', 'tempo_confidence', 'mode', 'key', 'key_confidence'],\n",
       "      dtype='<U25')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ranking = np.argsort(mi)[::-1]\n",
    "features = hdrs[2:]\n",
    "features.pop(features.index('popularity'))\n",
    "np.array(features)[feature_ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
